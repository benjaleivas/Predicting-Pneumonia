{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UFAQCELc8ltp"
   },
   "outputs": [],
   "source": [
    "## CHECKPOINT #2\n",
    "\n",
    "# There are three objectives for Checkpoint #2: \n",
    "#   - identify relevant metrics (2+) for assessing classifier accuracy\n",
    "#   - build a custom Neural Network:\n",
    "#       * with at least one input layer, one hidden layer, one output layer\n",
    "#   - initial analysis of this custom model\n",
    "#       * which would require a complete run through of trainning, validating \n",
    "#         testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MO5vVib5_TUR"
   },
   "outputs": [],
   "source": [
    "# FIRST OBJECTIVE\n",
    "\n",
    "# Choosing the relevant metrics is up to you. There are few things for things\n",
    "# for you to consider.\n",
    "\n",
    "# In choosing relevant metrics, I recommend considering at least one ACCURACY\n",
    "# METRIC AND at leat one LOSS FUNCTION! \n",
    "# 1) measure of accuracy: \n",
    "#   sci-kit learn's page on this could be useful for you:\n",
    "#   https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics\n",
    "#   there are many possible metrics to choose from: accuracy score, F1 score, \n",
    "#   precision-recall curve, etc\n",
    "# 2) loss functions:\n",
    "#   In class, we've seen Negative Log Loss, which works well for a binary\n",
    "#   or a multi-class classification. There is also cross-entropy, which is\n",
    "#   widely used for binary classifcation. There are other loss functions, too!\n",
    "#   This blog post is a good starting point: https://neptune.ai/blog/pytorch-loss-functions\n",
    "\n",
    "# CONSIDERATION: though this objective is listed first, I recommend coming to this\n",
    "# after you built your model. As you build the train/val/test process, assessing\n",
    "# accuracy and loss will be done pretty simply, often with a call of a single\n",
    "# function/method for each metric. Start with the metrics you've seen in class\n",
    "# and then consider branching out! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ynyYL4DbCNwT"
   },
   "outputs": [],
   "source": [
    "# SECOND OBJECTIVE\n",
    "\n",
    "# Building a custom neural network! The exciting part <3\n",
    "\n",
    "# FYI: HW4 will be a great introduction to using PyTorch to build a simple\n",
    "# neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading torchvision-0.15.1-cp39-cp39-macosx_10_9_x86_64.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /Users/jackgibson/opt/anaconda3/lib/python3.9/site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: numpy in /Users/jackgibson/opt/anaconda3/lib/python3.9/site-packages (from torchvision) (1.21.5)\n",
      "Requirement already satisfied: torch==2.0.0 in /Users/jackgibson/opt/anaconda3/lib/python3.9/site-packages (from torchvision) (2.0.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/jackgibson/opt/anaconda3/lib/python3.9/site-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: jinja2 in /Users/jackgibson/opt/anaconda3/lib/python3.9/site-packages (from torch==2.0.0->torchvision) (2.11.3)\n",
      "Requirement already satisfied: networkx in /Users/jackgibson/opt/anaconda3/lib/python3.9/site-packages (from torch==2.0.0->torchvision) (2.8.4)\n",
      "Requirement already satisfied: filelock in /Users/jackgibson/opt/anaconda3/lib/python3.9/site-packages (from torch==2.0.0->torchvision) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/jackgibson/opt/anaconda3/lib/python3.9/site-packages (from torch==2.0.0->torchvision) (4.3.0)\n",
      "Requirement already satisfied: sympy in /Users/jackgibson/opt/anaconda3/lib/python3.9/site-packages (from torch==2.0.0->torchvision) (1.10.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/jackgibson/opt/anaconda3/lib/python3.9/site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/jackgibson/opt/anaconda3/lib/python3.9/site-packages (from requests->torchvision) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jackgibson/opt/anaconda3/lib/python3.9/site-packages (from requests->torchvision) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jackgibson/opt/anaconda3/lib/python3.9/site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/jackgibson/opt/anaconda3/lib/python3.9/site-packages (from jinja2->torch==2.0.0->torchvision) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/jackgibson/opt/anaconda3/lib/python3.9/site-packages (from sympy->torch==2.0.0->torchvision) (1.2.1)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.15.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jackgibson/Documents/30254-ml/silent_p/provided_notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "61pG2bSzZuMe"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'data_module'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9c/588vmzx576d47gqhpgtw95v00000gn/T/ipykernel_76344/3028583510.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mread_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdata_module\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCustomImageDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'data_module'"
     ]
    }
   ],
   "source": [
    "from torchvision.io import read_image\n",
    "from data_module import CustomImageDataset\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A3NrRai5Z-iz",
    "outputId": "8aa885a4-ffe2-429c-b94a-20c2b8aa2053"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uPJe6akSEhFK"
   },
   "outputs": [],
   "source": [
    "# import our libraries\n",
    "import torch \n",
    "import torch.nn as nn # basic building block for neural neteorks\n",
    "import torch.nn.functional as F # import convolution functions like Relu\n",
    "import torch.optim as optim # optimzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6-EvHfmIZ_lO"
   },
   "outputs": [],
   "source": [
    "# 1: make your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1QN6b86UE0Y2"
   },
   "outputs": [],
   "source": [
    "# MY MODEL EXPECTS AN 512 x 512 IMAGE with dtype = float32\n",
    "\n",
    "class CustomNeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # inspire by Turing award winning LeCun, Bengio and Hinton's paper from 1998\n",
    "        # https://ieeexplore.ieee.org/document/726791 (cited more than 25,000 times!!!!!!!!!)\n",
    "        # code from https://blog.paperspace.com/writing-lenet5-from-scratch-in-python/ \n",
    "        self.LeNet = nn.Sequential(     \n",
    "            # convolutional layers            \n",
    "            nn.Sequential(                                            # FIRST LAYER: (INPUT LAYER)\n",
    "              nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0),    # CONVOLUTION \n",
    "              nn.BatchNorm2d(6),\n",
    "              nn.ReLU(),\n",
    "              nn.MaxPool2d(kernel_size = 2, stride = 2)),             # POOLING\n",
    "            nn.Sequential(                                            # SECOND LAYER: HIDDEN LAYER 1\n",
    "              nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),   # CONVOLUTION \n",
    "              nn.BatchNorm2d(16),\n",
    "              nn.ReLU(),\n",
    "              nn.MaxPool2d(kernel_size = 2, stride = 2)),             # POOLING\n",
    "            # fully connected layers\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(250000, 120),                                   # THIRD LAYER: LINEAR YEAR, HIDDEN LAYER 2\n",
    "            nn.ReLU(),                                                # HIDDEN LAYER's ACTIVATION FUNCION\n",
    "            nn.Linear(120, 84),                                       # FOURTH LAYER: LINEAR YEAR, HIDDEN LAYER 3\n",
    "            nn.ReLU(),                                                # HIDDEN LAYER's ACTIVATION FUNCION\n",
    "            # output layer\n",
    "            nn.Linear(84, 2)                                          # OUTPUT LAYER\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.LeNet(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lyUHBABjPcGh"
   },
   "outputs": [],
   "source": [
    "# RESOURCE FOR CHOOSING ACTIVATION FUNCTIONS\n",
    "# https://towardsdatascience.com/how-to-choose-the-right-activation-function-for-neural-networks-3941ff0e6f9c\n",
    "\n",
    "# RESOURCES ON CONVOLUTION: \n",
    "# NOTE: not necessary to implemenent a convolutional layer. this is helpful\n",
    "# IF you want to implement your own costum convolutional layer!\n",
    "# http://www.songho.ca/dsp/convolution/convolution.html#convolution_2d\n",
    "# http://www.songho.ca/dsp/convolution/convolution2d_example.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y0fdTAlkBKzO"
   },
   "outputs": [],
   "source": [
    "model = CustomNeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ACtoJg80E1IZ"
   },
   "outputs": [],
   "source": [
    "# 2: get your dataloaders from the first checkpoint!\n",
    "train_loader = #SOME CODE\n",
    "val_loader = #SOME CODE\n",
    "test_loader = #SOME CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ap8J5z4eC4PA"
   },
   "outputs": [],
   "source": [
    "# 3: Define a Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xPfEI2rRDPnE"
   },
   "outputs": [],
   "source": [
    "# 4: Train and validate the network\n",
    "EPOCHS = 50\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuarcies = []\n",
    "\n",
    "for _ in range(EPOCHS):  # loop over the dataset multiple times\n",
    "\n",
    "    # TRAIN\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "      # get the inputs; data is a list of [inputs, labels]\n",
    "      inputs, labels = data           # NOTE: depending on how you implemented your dataset class's __getitem__ it could be labels, inputs\n",
    "\n",
    "      # zero the parameter gradients\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      # forward + backward + optimize\n",
    "      outputs = model(inputs)\n",
    "      loss = criterion(outputs, labels)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # keep track of the loss\n",
    "      running_loss += loss.item()\n",
    "\n",
    "      # ALSO CALCULATE YOUR ACCURACY METRIC\n",
    "      \n",
    "    avg_train_loss = running_loss / (i + 1)     # i + 1 gives us the total number of batches in train dataloader\n",
    "    # CALCULATE AVERAGE ACCURACY METRIC\n",
    "    avg_train_loss = \n",
    "    train_losses.append(avg_train_loss)\n",
    "    train_accuracies.append(avg_train_acc)\n",
    "\n",
    "    #VALIDATE\n",
    "    # in the validation part, we don't want to keep track of the gradients \n",
    "    model.eval()            \n",
    "    \n",
    "    # implement a similar loop!\n",
    "    # but you can leave out loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DXRfmBsiLmUe"
   },
   "outputs": [],
   "source": [
    "# 5: Test!\n",
    "\n",
    "# FOR TESTING YOU DON'T HAVE TO ITERATE OVER MULTIPLE EPOCHS\n",
    "# JUST ONE PASS OVER THE TEST DATALOADER!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GJfuHA1fM-ve"
   },
   "outputs": [],
   "source": [
    "# 6: ANAYLZE (i.e. 3RD OBJECTIVE)\n",
    "\n",
    "# YOU CAN MAKE GRAPHS of TRAIN AND VAL LOSSES OVER EPOCHS, etc!\n",
    "# YOU CAN ALSO DO MULTIPLE TRAININGS, CHOOSING A DIFFERENT LOSS FUNCTION\n",
    "# FOR EACH TRAINING RUN, AND THEN YOU COULD COMPARE HOW WHICH LOSS FUNCTION\n",
    "# LEADS TO THE BEST LOSSES OR BEST ACCURACIES\n",
    "\n",
    "# ALSO YOU COULD TRAIN USING DIFFERENT OPTIMIZERS!\n",
    "\n",
    "# SO MUCH YOU COULD DO!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "9e24dd9cc808ab50800f409e27684ef1d7d2c09bc61702024ae72f277d93666d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
