{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Evaluation\n",
    "\n",
    "This notebook provides code to replicate how we tested and evaluated different versions of our logistic regression.\n",
    "\n",
    "Models were created using each of the four transformations: base, color agumenation only, edge augmentation only, and both color and edge augmentation. Each model was trained for 15 epochs with training and validation metrics calculated per epoch. Graphs that depict how loss, accuracy and recall change of the course of training were created. Finally, the model was tested with the test data, with these performance metrics also displayed within the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Eval\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F \n",
    "from torch.utils.data import DataLoader\n",
    "from process.data_module import CustomImageDataset\n",
    "from process.logistic_regression import LogisticRegression, accuracy, recall, evaluate, fit\n",
    "from process.transforms import base_transforms, edges_transforms, color_transforms, both_transforms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original x-rays and apply transformations\n",
    "training_data = CustomImageDataset(\"data/paths/train.csv\", \"data/train/\", base_transforms)\n",
    "validation_data = CustomImageDataset(\"data/paths/val.csv\", \"data/val/\", base_transforms)\n",
    "test_data = CustomImageDataset(\"data/paths/test.csv\", \"data/test/\", base_transforms)\n",
    "\n",
    "# Load groups/batches of x-rays for analysis\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True, num_workers=3, pin_memory=True)\n",
    "validation_dataloader = DataLoader(validation_data, batch_size=64, shuffle=True, num_workers=3, pin_memory=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True, num_workers=3, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "labels = 2\n",
    "epochs = 15\n",
    "image_size = 256*256\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'accuracy': 0.888888955116272, 'recall': 0.9404149055480957}]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(image_size, labels)\n",
    "\n",
    "for images, _ in train_dataloader:\n",
    "    output = model(images.type(torch.float32))\n",
    "\n",
    "fit(epochs, learning_rate, model, train_dataloader, test_dataloader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
